{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start_date</th>\n",
       "      <th>fire_ID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>size</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>start_DOY</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_DOY</th>\n",
       "      <th>duration</th>\n",
       "      <th>expansion</th>\n",
       "      <th>fire_line</th>\n",
       "      <th>speed</th>\n",
       "      <th>direction</th>\n",
       "      <th>direction_s</th>\n",
       "      <th>landcover</th>\n",
       "      <th>landcover_s</th>\n",
       "      <th>tile_ID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2566038</td>\n",
       "      <td>2005-07-02</td>\n",
       "      <td>584383</td>\n",
       "      <td>-6.7438</td>\n",
       "      <td>22.3535</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.85</td>\n",
       "      <td>183</td>\n",
       "      <td>2005-07-02</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>Woody savannas</td>\n",
       "      <td>h20v09</td>\n",
       "      <td>POLYGON ((22.35037406370953 -6.74166666610823,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3258696</td>\n",
       "      <td>2005-12-06</td>\n",
       "      <td>250743</td>\n",
       "      <td>8.8188</td>\n",
       "      <td>3.2881</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.85</td>\n",
       "      <td>340</td>\n",
       "      <td>2005-12-06</td>\n",
       "      <td>340</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>9</td>\n",
       "      <td>Savannas</td>\n",
       "      <td>h18v08</td>\n",
       "      <td>POLYGON ((3.2846822924633345 8.820833332498871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5600233</td>\n",
       "      <td>2008-07-27</td>\n",
       "      <td>640420</td>\n",
       "      <td>-15.0104</td>\n",
       "      <td>27.6267</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.70</td>\n",
       "      <td>209</td>\n",
       "      <td>2008-07-30</td>\n",
       "      <td>212</td>\n",
       "      <td>4</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>north</td>\n",
       "      <td>9</td>\n",
       "      <td>Savannas</td>\n",
       "      <td>h20v10</td>\n",
       "      <td>POLYGON ((27.620844048341272 -15.0041666653687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3644868</td>\n",
       "      <td>2006-09-10</td>\n",
       "      <td>637240</td>\n",
       "      <td>-16.2812</td>\n",
       "      <td>24.7243</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4.63</td>\n",
       "      <td>253</td>\n",
       "      <td>2006-09-10</td>\n",
       "      <td>253</td>\n",
       "      <td>1</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>Woody savannas</td>\n",
       "      <td>h20v10</td>\n",
       "      <td>POLYGON ((24.720269461331405 -16.2791666652545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7274504</td>\n",
       "      <td>2010-09-24</td>\n",
       "      <td>396369</td>\n",
       "      <td>-12.9688</td>\n",
       "      <td>18.0960</td>\n",
       "      <td>1.71</td>\n",
       "      <td>6.48</td>\n",
       "      <td>267</td>\n",
       "      <td>2010-09-25</td>\n",
       "      <td>268</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4</td>\n",
       "      <td>southeast</td>\n",
       "      <td>8</td>\n",
       "      <td>Woody savannas</td>\n",
       "      <td>h19v10</td>\n",
       "      <td>POLYGON ((18.090459431003897 -12.9666666655510...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  start_date  fire_ID      lat      lon  size  perimeter  \\\n",
       "0     2566038  2005-07-02   584383  -6.7438  22.3535  0.21       1.85   \n",
       "1     3258696  2005-12-06   250743   8.8188   3.2881  0.21       1.85   \n",
       "2     5600233  2008-07-27   640420 -15.0104  27.6267  0.86       3.70   \n",
       "3     3644868  2006-09-10   637240 -16.2812  24.7243  1.29       4.63   \n",
       "4     7274504  2010-09-24   396369 -12.9688  18.0960  1.71       6.48   \n",
       "\n",
       "   start_DOY    end_date  end_DOY  duration  expansion  fire_line  speed  \\\n",
       "0        183  2005-07-02      183         1       0.21       0.46   0.46   \n",
       "1        340  2005-12-06      340         1       0.21       0.46   0.46   \n",
       "2        209  2008-07-30      212         4       0.21       0.46   0.50   \n",
       "3        253  2006-09-10      253         1       1.29       2.78   0.85   \n",
       "4        267  2010-09-25      268         2       0.86       1.85   0.86   \n",
       "\n",
       "   direction direction_s  landcover     landcover_s tile_ID  \\\n",
       "0          0        none          8  Woody savannas  h20v09   \n",
       "1          0        none          9        Savannas  h18v08   \n",
       "2          1       north          9        Savannas  h20v10   \n",
       "3          0        none          8  Woody savannas  h20v10   \n",
       "4          4   southeast          8  Woody savannas  h19v10   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((22.35037406370953 -6.74166666610823,...  \n",
       "1  POLYGON ((3.2846822924633345 8.820833332498871...  \n",
       "2  POLYGON ((27.620844048341272 -15.0041666653687...  \n",
       "3  POLYGON ((24.720269461331405 -16.2791666652545...  \n",
       "4  POLYGON ((18.090459431003897 -12.9666666655510...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/hannahwurzel/Desktop/dl-firefighters/DL-firefighters/data/data660k.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'start_date', 'fire_ID', 'lat', 'lon', 'size',\n",
       "       'perimeter', 'start_DOY', 'end_date', 'end_DOY', 'duration',\n",
       "       'expansion', 'fire_line', 'speed', 'direction', 'direction_s',\n",
       "       'landcover', 'landcover_s', 'tile_ID', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662530, 20)\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows and columns\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0     0\n",
      "start_date     0\n",
      "fire_ID        0\n",
      "lat            0\n",
      "lon            0\n",
      "size           0\n",
      "perimeter      0\n",
      "start_DOY      0\n",
      "end_date       0\n",
      "end_DOY        0\n",
      "duration       0\n",
      "expansion      0\n",
      "fire_line      0\n",
      "speed          0\n",
      "direction      0\n",
      "direction_s    0\n",
      "landcover      0\n",
      "landcover_s    0\n",
      "tile_ID        0\n",
      "geometry       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature  Importance\n",
      "8  num__fire_line    1.163352\n",
      "3       num__size    0.413359\n",
      "9      num__speed    0.044186\n",
      "6   num__duration    0.035140\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already loaded the dataframe 'df' with (662530, 20) shape\n",
    "\n",
    "# Separate target variable (expansion) from the features\n",
    "X = df.drop(columns=['expansion', 'geometry'])\n",
    "y = df['expansion']\n",
    "\n",
    "# Lists of nominal and ordinal categorical features\n",
    "nominal_categorical_features = ['start_date', 'end_date', 'direction_s', 'landcover_s', 'tile_ID']\n",
    "ordinal_categorical_features = ['fire_ID', 'lat', 'lon', 'size', 'start_DOY', 'end_DOY', 'duration', 'perimeter', 'fire_line', 'speed', 'direction', 'landcover']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: Define the transformations for the features\n",
    "ordinal_transformer = StandardScaler()\n",
    "nominal_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Column transformer to apply different preprocessing to nominal and ordinal features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', ordinal_transformer, ordinal_categorical_features),\n",
    "        ('cat', nominal_transformer, nominal_categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the ElasticNet regression model\n",
    "alpha = 0.1  # Set the regularization strength (decrease the value to reduce regularization)\n",
    "l1_ratio = 0.5  # Set the balance between L1 and L2 penalties (0.5 for equal L1 and L2, 1.0 for LASSO)\n",
    "elastic_net_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "\n",
    "# Combine preprocessing and model into a single pipeline\n",
    "elastic_net_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('elasticnet', elastic_net_model)])\n",
    "\n",
    "# Fit the ElasticNet model to the training data\n",
    "elastic_net_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances (coefficients) from the ElasticNet model\n",
    "# Note: Coefficients with value 0 are considered unimportant and are removed by ElasticNet\n",
    "feature_names = preprocessor.get_feature_names_out(input_features=X_train.columns)\n",
    "feature_importances = elastic_net_model.coef_\n",
    "\n",
    "# Create a dataframe to show the feature importance values with their corresponding feature names\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': np.abs(feature_importances)})\n",
    "\n",
    "# Sort the dataframe by importance (descending order) to see the most important features first\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Filter to keep only the features with non-zero importance values\n",
    "non_zero_features_df = feature_importance_df[feature_importance_df['Importance'] != 0]\n",
    "\n",
    "print(non_zero_features_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training using Tree-based feature importance results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "data_temp = df.drop('expansion', axis=1)\n",
    "df_norm = (data_temp-data_temp.min())/(data_temp.max()-data_temp.min())\n",
    "df_norm = pd.concat((df_norm, df.expansion), 1)\n",
    "\n",
    "# Assuming 'expansion' is the name of your target variable column\n",
    "X = df_norm[[\"fire_line\", \"speed\", \"size\", \"perimeter\"]]\n",
    "y = df[\"expansion\"]\n",
    "\n",
    "# Splitting the data into training and testing sets (80:20 ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVR Model\n",
    "svr_model = SVR(kernel=\"linear\")\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Linear Regression\n",
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the training set \n",
    "svr_train_predictions = svr_model.predict(X_train)\n",
    "linear_reg_train_predictions = linear_reg_model.predict(X_train)\n",
    "rf_train_predictions = rf_model.predict(X_train)\n",
    "\n",
    "# Calculating metrics for SVR on the training set\n",
    "svr_mae_train = mean_absolute_error(y_train, svr_train_predictions)\n",
    "svr_mse_train = mean_squared_error(y_train, svr_train_predictions)\n",
    "svr_rmse_train = np.sqrt(svr_mse_train)\n",
    "svr_r2_train = r2_score(y_train, svr_train_predictions)\n",
    "\n",
    "# Calculating metrics for Linear Regression on the training set\n",
    "linear_reg_mae_train = mean_absolute_error(y_train, linear_reg_train_predictions)\n",
    "linear_reg_mse_train = mean_squared_error(y_train, linear_reg_train_predictions)\n",
    "linear_reg_rmse_train = np.sqrt(linear_reg_mse_train)\n",
    "linear_reg_r2_train = r2_score(y_train, linear_reg_train_predictions)\n",
    "\n",
    "# Calculating metrics for Random Forest Regressor on the training set\n",
    "rf_mae_train = mean_absolute_error(y_train, rf_train_predictions)\n",
    "rf_mse_train = mean_squared_error(y_train, rf_train_predictions)\n",
    "rf_rmse_train = np.sqrt(rf_mse_train)\n",
    "rf_r2_train = r2_score(y_train, rf_train_predictions)\n",
    "\n",
    "# Printing the metrics for SVR\n",
    "print(\"Linear Regression - Training Set\")\n",
    "print(\"MAE:\", svr_mae_train)\n",
    "print(\"MSE:\", svr_mse_train)\n",
    "print(\"RMSE:\", svr_rmse_train)\n",
    "print(\"R²:\", svr_r2_train)\n",
    "\n",
    "# Printing the metrics for Linear Regression\n",
    "print(\"Linear Regression - Training Set\")\n",
    "print(\"MAE:\", linear_reg_mae_train)\n",
    "print(\"MSE:\", linear_reg_mse_train)\n",
    "print(\"RMSE:\", linear_reg_rmse_train)\n",
    "print(\"R²:\", linear_reg_r2_train)\n",
    "\n",
    "# Printing the metrics for Random Forest Regressor\n",
    "print(\"\\nRandom Forest Regressor - Training Set\")\n",
    "print(\"MAE:\", rf_mae_train)\n",
    "print(\"MSE:\", rf_mse_train)\n",
    "print(\"RMSE:\", rf_rmse_train)\n",
    "print(\"R²:\", rf_r2_train)\n",
    "\n",
    "# Predicting on the test set for all models\n",
    "svr_test_predictions = svr_model.predict(X_test)\n",
    "linear_reg_test_predictions = linear_reg_model.predict(X_test)\n",
    "rf_test_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Calculating metrics for SVR on the test set\n",
    "svr_mae_test = mean_absolute_error(y_test, svr_test_predictions)\n",
    "svr_mse_test = mean_squared_error(y_test, svr_test_predictions)\n",
    "svr_rmse_test = np.sqrt(svr_mse_test)\n",
    "svr_r2_test = r2_score(y_test, svr_test_predictions)\n",
    "\n",
    "# Calculating metrics for Linear Regression on the test set\n",
    "linear_reg_mae_test = mean_absolute_error(y_test, linear_reg_test_predictions)\n",
    "linear_reg_mse_test = mean_squared_error(y_test, linear_reg_test_predictions)\n",
    "linear_reg_rmse_test = np.sqrt(linear_reg_mse_test)\n",
    "linear_reg_r2_test = r2_score(y_test, linear_reg_test_predictions)\n",
    "\n",
    "# Calculating metrics for Random Forest Regressor on the test set\n",
    "rf_mae_test = mean_absolute_error(y_test, rf_test_predictions)\n",
    "rf_mse_test = mean_squared_error(y_test, rf_test_predictions)\n",
    "rf_rmse_test = np.sqrt(rf_mse_test)\n",
    "rf_r2_test = r2_score(y_test, rf_test_predictions)\n",
    "\n",
    "# Printing the metrics for SVR on the test set\n",
    "print(\"\\nLinear Regression - Test Set\")\n",
    "print(\"MAE:\", svr_mae_test)\n",
    "print(\"MSE:\", svr_mse_test)\n",
    "print(\"RMSE:\", svr_rmse_test)\n",
    "print(\"R²:\", svr_r2_test)\n",
    "\n",
    "# Printing the metrics for Linear Regression on the test set\n",
    "print(\"\\nLinear Regression - Test Set\")\n",
    "print(\"MAE:\", linear_reg_mae_test)\n",
    "print(\"MSE:\", linear_reg_mse_test)\n",
    "print(\"RMSE:\", linear_reg_rmse_test)\n",
    "print(\"R²:\", linear_reg_r2_test)\n",
    "\n",
    "# Printing the metrics for Random Forest Regressor on the test set\n",
    "print(\"\\nRandom Forest Regressor - Test Set\")\n",
    "print(\"MAE:\", rf_mae_test)\n",
    "print(\"MSE:\", rf_mse_test)\n",
    "print(\"RMSE:\", rf_rmse_test)\n",
    "print(\"R²:\", rf_r2_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for model metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['SVR', 'Linear Regression', 'Random Forest Regressor'],\n",
    "    'MAE (Test Set)': [svr_mae_test, linear_reg_mae_test, rf_mae_test],\n",
    "    'MSE (Test Set)': [svr_mse_test, linear_reg_mse_test, rf_mse_test],\n",
    "    'RMSE (Test Set)': [svr_rmse_test, linear_reg_rmse_test, rf_rmse_test],\n",
    "    'R² (Test Set)': [svr_r2_test, linear_reg_r2_test, rf_r2_test]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "metrics_df.plot(x='Model', kind='bar')\n",
    "plt.title('Model Performance Comparison - Test Set')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison Scatter Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, svr_test_predictions, alpha=0.5, label='SVR')\n",
    "plt.scatter(y_test, linear_reg_test_predictions, alpha=0.5, label='Linear Regression')\n",
    "plt.scatter(y_test, rf_test_predictions, alpha=0.5, label='Random Forest Regressor')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Model Comparison - Actual vs Predicted (Test Set)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
